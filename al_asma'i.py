# -*- coding: utf-8 -*-
"""Al-Asma'i.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18SBS6lOfv11vNVkMqlvv6n7xP2QovWHg
"""

from IPython.core.display import display, HTML

html_code = """
<div style="text-align: center;">
    <h1 style="font-size: 4em; margin: 0; padding: 20px; background: linear-gradient(90deg, #ff8c00, #ffa500, #ff8c00); -webkit-background-clip: text; color: transparent; animation: colorChange 5s infinite;">
        Ø§Ù„Ø£ØµÙ…Ø¹ÙŠ:Ø§Ù„Ø´Ø§Ø¹Ø± Ø§Ù„Ø±Ù‚Ù…ÙŠ
    </h1>
    <h2 style="font-size: 2em; color: #ffa500; margin: 0; animation: colorChange 5s infinite;">
        (Al-Asma'i Al-sha'ir Al-Raqami) - "Al-Asmai: The digital poet"
    </h2>
    <p style="font-size: 1.5em; color: #ffffff; margin-top: 20px;">
        by <a href="https://github.com/alwalid54321" style="color: #00cec9; text-decoration: none;">alwalid54321</a>
    </p>
</div>

<style>
@keyframes colorChange {
    0% { color: #ff8c00; }
    25% { color: #ffa500; }
    50% { color: #ff4500; }
    75% { color: #ff8c00; }
    100% { color: #ffa500; }
}
</style>
"""

display(HTML(html_code))

"""# Hello, ğŸ–‹ğŸ“œ


We will be presenting the final project for the Data Science and Artificial Intelligence. Through this project, we use artificial intelligence to convert textual poetry into a multimedia experience of generated images and background audio. ğŸ¨ğŸ”Š

We are trying to explore Arabic poetry and shed light on its aesthetics and artistic depth in an innovative and engaging way.


To achieve this, we will:

1. ğŸ’» Install and set up the necessary AI libraries for generating images and audio, such as OpenAI and ElevenLabs, and you will find the data along with the main  file in Github.
2. ğŸ”Œ Prepare the application programming interfaces (APIs) to properly interact with these libraries.
3. ğŸ¨ğŸ”Š Utilize these APIs to generate the appropriate images and audio for the Arabic poetry, and you may also need huggingface tikonizer API.
4. ğŸ“½ï¸ Integrate the multimedia elements (images and audio) into a cohesive experience, synchronizing the image display with the audio playback.
5. ğŸ‰Present this integrated poetic multimedia experience and emphasize the value it adds to Arabic poetry arts.

by: **["alwalid54321"](https://github.com/alwalid54321)** and help from "Atheer" and "Lujain"

## Setup
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q openai elevenlabs pyarabic scikit-learn pydub moviepy transformers torch Flask flask-ngrok transformers torch Flask pyngrok

"""### Imports

"""

import io
import re
import enum
import tempfile
import textwrap
from dataclasses import dataclass

import requests
import numpy as np
import pandas as pd
from PIL import Image
from IPython import display

import pyarabic.araby as araby
from pydub import AudioSegment
from moviepy.editor import (
    ImageClip,
    AudioFileClip,
    CompositeVideoClip,
    transfx,
    concatenate_videoclips,
)

from openai import OpenAI

import elevenlabs
from elevenlabs.client import ElevenLabs

from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
import torch
from torch.utils.data import Dataset
from flask import Flask, render_template_string, request
from pyngrok import ngrok
import pickle
import hashlib

"""### Utilities"""

def arabic_html(text):
    return display.HTML(f'<p style="direction: rtl">{text}</p>'.replace('\n', '<br>'))


def save_slide_show(video_path, image_audio: list[tuple[Image.Image, AudioSegment]]):
    images, audios = [], []
    for image, audio in image_audio:
        images.append(image)
        with tempfile.NamedTemporaryFile('wb', suffix='.wav') as file:
            audio.export(file, format='wav')
            audios.append(AudioFileClip(file.name))
    assert str(video_path).endswith('.mp4'), 'extension must be .mp4'
    with open(video_path, 'wb') as file:
        concatenate_videoclips([
            CompositeVideoClip([
                ImageClip(
                    np.asarray(image),
                    duration=audio.duration,
                    transparent=False,
                )
                .set_audio(audio)
                .fx(transfx.fadein, duration=1)
            ])
            for image, audio in zip(images, audios)
        ]).write_videofile(file.name, fps=24)

"""#### Elevenlabs

"""

elevenlabs_client = ElevenLabs(api_key="Your_api")

def generate_audio(text: str, play: bool = False) -> AudioSegment:
    audio = b''.join(elevenlabs_client.generate(
        text=text,
        voice=elevenlabs.Voice(
            voice_id="lPf4CUKNuZyDy1AmnqKT",
            settings=elevenlabs.VoiceSettings(
                style=0.0,
                stability=0.71,
                similarity_boost=0.5,
                use_speaker_boost=True,
            ),
        ),
        model="eleven_multilingual_v2",
        output_format="mp3_44100_128",  # MP3 with 44.1 khz sampling rate and 128 kbps compression
    ))
    if play:
        elevenlabs.play(audio, notebook=True)
    return AudioSegment.from_mp3(io.BytesIO(audio))

"""In this code generates an audio file from the input text text1 using the ElevenLabs API, with specific voice settings, and plays the audio within the notebook environment.

#### OpenAI
"""

openai_client = OpenAI(api_key="Your_api")

def ask_gpt(instruction: str, prompt: str, model: str = "gpt-4o", temperature: float = 0) -> str:
    response = openai_client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": instruction},
            {"role": "user", "content": prompt},
        ],
        temperature=temperature,
        max_tokens=2000,
    )
    return response.choices[0].message.content

"""This code has been trained to respond to the following operations: taking poetic verses as input, then dividing the verses into related parts, then explaining each verse, and then writing a descriptive visualization for each verse so that we get images that express each verse, effectively producing images that capture the essence of each poetic line.

#### DALL-E
"""

def generate_image(prompt, model="dall-e-3", size="1024x1024", n=1):
    response = openai_client.images.generate(
        model=model,
        prompt=prompt,
        size=size,
        quality="standard",
        n=n,
    )
    image_url = response.data[0].url
    return Image.open(requests.get(image_url, stream=True).raw)

"""A function called generate_image is called, which takes a prompt as an input parameter and generates an image based on that prompt using the DALL-E 3 model.

This function can be used to generate an image based on a specific text prompt using the DALL-E 3 model. The generated image can be accessed and used for various purposes, such as displaying it on a website or using it in an application.

## Poems Data
"""

@dataclass(frozen=True)
class EraAttire:
    arabic: str
    name: str
    men: str
    women: str

    def __repr__(self):
        return f"""To get a sense of the style, this image is set in \
the {self.name} where the prevalent attire for both genders was as follows:
Men: {self.men}
Women: {self.women}"""


class Era(enum.Enum):
    JAHILI = EraAttire(
        arabic="Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø¬Ø§Ù‡Ù„ÙŠ",
        name="Pre-Islamic Jahiliyyah era",
        men="two-piece garment that covered the lower and upper parts \
of their bodies along with turbans and red hoods",
        women="jewel-encrusted head coverings and dresses with striped or pleated patterns",
    )
    ANDALUSI = EraAttire(
        arabic="Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø£Ù†Ø¯Ù„Ø³ÙŠ",
        name="Islamic Andalusian era",
        men="long tunics with long sleeves and embroidered trim at the edges, \
along with loose-fitting pants and belts wrapped around the waist",
        women="traditional, ornate clothing decorated with golden embroidery and patterns. \
On their heads, they wore a golden crown adorned with precious stones, from which a sheer veil hung",
    )
    ABBASI = EraAttire(
        arabic="Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠ",
        name="Islamic age of the Abbasid chaliphate",
        men="black cloak and turbans with red slippers",
        women="head coverings or veils adorned with \
golden chains and gemstones along white robe with white buttons and pants",
    )
    MAMLUK = EraAttire(
        arabic="Ø§Ù„Ø¹ØµØ± Ø§Ù„Ù…Ù…Ù„ÙˆÙƒÙŠ",
        name="Islamic era of the Mamluk",
        men="shirt with a long, white outer robe over it, decorated with red or blue stripes",
        women="wore loose, long shirts with wide and long sleeves. \
On their heads, they wore a scarf embroidered with ornate patterns and adorned with precious stones",
    )
    OTTOMAN = EraAttire(
        arabic="Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø¹Ø«Ù…Ø§Ù†ÙŠ",
        name="Islamic era of the Ottoman empire",
        men="wore multi-layered attire \
they also wore a long cloak, embroidered on the sleeves and torso. \
On their heads, they wore a large white turban",
        women="wore dresses made of multiple layers and were distinguished by embroidery on the sleeves, collars, and hems \
they also wore wide belts wrapped around the waist",
    )
    MODERN = EraAttire(
        arabic="Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø­Ø¯ÙŠØ«",
        name="Modern Islamic and Arabic era",
        men="white robe called 'thobe' with a turban 'shumagh' on their heads",
        women="traditional clothes such as the abaya and hijab",
    )


era_map = dict((e.value.arabic, e) for e in Era)

"""this code provides a comprehensive reference for the fashion and clothing styles associated with different eras in Islamic history, which could be useful for tasks such as historical research, costume design, or creating visually accurate depictions of characters from these time periods."""

@dataclass
class Verse:
    part1: str
    part2: str

    @property
    def verse(self):
        return araby.strip_tashkeel(repr(self))

    def __repr__(self):
        return f'{self.part1} ... {self.part2}'


@dataclass
class Poem:
    era: Era
    poet: str
    style: str
    themes: str
    verses: list[Verse]

    def get_verses(self, index=None):
        verses = self.verses if index is None else self.verses[index]
        verses = verses if isinstance(verses, list) else [verses]
        return '\n'.join(map(str, verses))

    def get_snippet(self, index=None):
        return f"""Ø§Ù„Ø¹ØµØ±: "{self.era.value.arabic}"
Ø§Ù„Ø´Ø§Ø¹Ø±: "{self.poet}"
Ø§Ù„Ø¨Ø­Ø±: "{self.style}"
Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª: "{self.themes}"
Ø§Ù„Ø´Ø¹Ø±:
```
{self.get_verses(index)}
```"""

    def __repr__(self):
        return self.get_snippet()

    def __getitem__(self, index):
        return self.verses[index]

    def __len__(self):
        return len(self.verses)

df = pd.read_csv(
    "/content/poems.csv",
    usecols=["poet_name", "poet_era", "poem_title", "poem_theme", "poem_verses"],
).dropna(subset="poet_era")


def row_to_poem(row):
    poem = Poem(
        era=era_map[row["poet_era"]],
        poet=row["poet_name"],
        style=row["poet_era"],
        themes=row["poem_theme"],
        verses=[],
    )
    verses = eval(row["poem_verses"])
    for i in range(0, (len(verses) // 2) * 2, 2):
        poem.verses.append(Verse(verses[i], verses[i + 1]))
    return poem

poems = df.apply(row_to_poem, axis=1)

"""We have selected this dataset as it contains classical Arabic poetry, where each row represents a different poem. The poems cover a diverse range of topics, including religious, philosophical and personal themes. The data set provides valuable information about the poets, their backgrounds, and the poetic traditions they were a part of.

This data set helps us in linking the extracted themes and atmospheres from the poetic text to generating appropriate images for them. It also allows the models to learn to generate images that accurately depict the content of the diverse poetic texts, covering a wide range of religious, philosophical and personal topics in the poems. This will enable the models to generate diverse and expressive images representing these varied contents.

## Era Classification

We trained a logistic regression model to classify the era of the poet for Arabic poetry based on the text of the poems, where we initially loaded the "arbml/ashaar" dataset of Arabic poems and preprocessed it, including filtering the poems from the "Diwan" website and removing the diacritical marks. We explored the distribution of the poets' eras in the dataset, which shows that the majority are from the "Modern Era" and "Abbasid Era", with the least being from the "Andalusian Era".

The model achieves an overall accuracy of 0.59 on the test set.
"""

class PoemsDataset(Dataset):
    def __init__(self, poems, labels, tokenizer, max_len):
        self.poems = poems
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.poems)

    def __getitem__(self, item):
        poem = str(self.poems[item])
        label = self.labels[item]

        encoding = self.tokenizer.encode_plus(
            poem,
            add_special_tokens=True,
            max_length=self.max_len,
            return_token_type_ids=False,
            padding='max_length',
            truncation=True,
            return_attention_mask=True,
            return_tensors='pt',
        )

        return {
            'poem_text': poem,
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

class EraClassifier:
    def __init__(self, model_name="aubmindlab/bert-base-arabert", seed=123, max_len=128):
        self.seed = seed
        self.is_fit = False
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)  # Adjust num_labels based on your data
        self.max_len = max_len

    def fit(self, df):
        df = df[["poem_verses", "poet_era"]].dropna(subset=["poet_era"])
        df["poem_verses"] = df["poem_verses"].apply(araby.strip_tashkeel)

        # Assuming poet_era is already label encoded, if not, you need to encode it
        X_train, X_test, y_train, y_test = train_test_split(
            df["poem_verses"], df["poet_era"],
            test_size=0.2,
            random_state=self.seed,
        )

        train_dataset = PoemsDataset(X_train.to_numpy(), y_train.to_numpy(), self.tokenizer, self.max_len)
        test_dataset = PoemsDataset(X_test.to_numpy(), y_test.to_numpy(), self.tokenizer, self.max_len)

        training_args = TrainingArguments(
            output_dir='./results',
            num_train_epochs=3,
            per_device_train_batch_size=16,
            per_device_eval_batch_size=16,
            warmup_steps=500,
            weight_decay=0.01,
            logging_dir='./logs',
            logging_steps=10,
        )

        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=test_dataset,
            tokenizer=self.tokenizer
        )

        trainer.train()
        self.is_fit = True

        predictions = trainer.predict(test_dataset)
        y_pred = predictions.predictions.argmax(-1)

        labels = [era_map[n].name for n in sorted(y_test.unique())]
        return classification_report(y_test, y_pred, target_names=labels)

    def predict(self, poems):
        inputs = self.tokenizer(poems, padding=True, truncation=True, max_length=self.max_len, return_tensors="pt")
        outputs = self.model(**inputs)
        predictions = outputs.logits.argmax(dim=-1).tolist()
        return predictions


era_classifier = EraClassifier()
# print(era_classifier.fit(df))

# class EraClassifier:
#     def __init__(self, seed=123):
#         self.seed = seed
#         self.is_fit = False
#         self.vectorizer = TfidfVectorizer(max_features=52000)
#         self.model = LogisticRegression(random_state=seed, class_weight="balanced")

#     def fit(self, df):
#         df = df[["poem_verses", "poet_era"]].dropna(subset=["poet_era"])
#         df["poem_verses"] = df["poem_verses"].apply(araby.strip_tashkeel)
#         inputs = pd.DataFrame(
#             self.vectorizer.fit_transform(df["poem_verses"]).toarray(),
#             columns=self.vectorizer.get_feature_names_out(),
#         )
#         X_train, X_test, y_train, y_test = train_test_split(
#             inputs, df["poet_era"],
#             test_size=0.2,
#             random_state=self.seed,
#         )
#         self.model.fit(X_train, y_train)
#         self.is_fit = True
#         y_pred = self.model.predict(X_test)
#         labels = [era_map[n].name for n in sorted(y_test.unique())]
#         return classification_report(y_test, y_pred, target_names=labels)

#     def predict(self, poems):
#         # poems = [araby.strip_tashkeel(p) for p in poems]
#         inputs = pd.DataFrame(
#             self.vectorizer.transform(poems).toarray(),
#             columns=self.vectorizer.get_feature_names_out(),
#         )
#         return self.model.predict(inputs)


# era_classifier = EraClassifier()
# # print(era_classifier.fit(df))

if era_classifier.is_fit:
    print(era_classifier.predict([
        """
    Ù…Ø§ ÙƒÙÙ†ØªÙ Ø£ÙÙˆÙÙ‘Ù„Ù Ù…ÙÙ† ØªÙÙÙØ±ÙÙ‘Ù‚Ù Ø´ÙÙ…Ù„ÙÙ‡Ù ... ÙˆÙØ±ÙØ£Ù‰ Ø§Ù„ØºÙØ¯Ø§Ø©Ù Ù…ÙÙ†Ù Ø§Ù„ÙÙØ±Ø§Ù‚Ù ÙŠÙÙ‚ÙŠÙ†Ø§
    ÙˆÙØ¨ÙØ¯Ø§Ø±ÙØ©Ù Ø§Ù„Ø³ÙÙ„ÙÙ…Ù Ø§Ù„ÙÙ‘ØªÙŠ Ø´ÙÙˆÙÙ‘Ù‚ØªÙÙ‡Ø§ ... Ø¯ÙÙ…ÙÙ†ÙŒ ÙŠÙØ¸ÙÙ„ÙÙ‘ Ø­ÙÙ…Ø§Ù…ÙÙ‡Ø§ ÙŠÙØ¨ÙƒÙŠÙ†Ø§
        """.strip(),
    ]))

"""## Explanation and Illustration"""

def explain_and_illustrate(poem: Poem, index: int = None):
    if index is None:
        for i in range(len(poem)):
            explain_and_illustrate(poem, i)
        return poem
    verse = poem.verses[index]
    if getattr(verse, 'illustration_en', ''):  # don't
        return verse
    example_poem = Poem(
        era=Era.ABBASI,
        poet="Ø§Ø¨Ùˆ Ø§Ù„Ø¹ØªØ§Ù‡ÙŠØ©",
        style="Ø¨Ø­Ø± Ø§Ù„Ø·ÙˆÙŠÙ„",
        themes="Ù‚ØµØ§Ø¦Ø¯ Ø¹Ø§Ù…Ø©",
        verses=[
            Verse(
                "Ù„ÙØ¹ÙÙ…Ø±ÙÙƒÙ Ù…Ø§ Ø§Ù„Ø¯ÙÙ†ÙŠØ§ Ø¨ÙØ¯Ø§Ø±Ù Ø¨ÙÙ‚Ø§Ø¡Ù",
                "ÙƒÙÙØ§ÙƒÙ Ø¨ÙØ¯Ø§Ø±Ù Ø§Ù„Ù…ÙÙˆØªÙ Ø¯Ø§Ø±Ù ÙÙÙ†Ø§Ø¡Ù"
            ),
            Verse(
                "ÙÙÙ„Ø§ ØªÙØ¹Ø´ÙÙ‚Ù Ø§Ù„Ø¯ÙÙ†ÙŠØ§ Ø£ÙØ®ÙÙŠÙ‘Ù ÙÙØ¥ÙÙ†Ù‘ÙÙ…Ø§",
                "ØªÙØ±Ù‰ Ø¹Ø§Ø´ÙÙ‚Ù Ø§Ù„Ø¯ÙÙ†ÙŠØ§ Ø¨ÙØ¬ÙÙ‡Ø¯Ù Ø¨ÙÙ„Ø§Ø¡Ù"
            ),
            Verse(
                "Ø­ÙÙ„Ø§ÙˆÙØªÙÙ‡Ø§ Ù…ÙÙ…Ø²ÙˆØ¬ÙØ©ÙŒ Ø¨ÙÙ…ÙØ±Ø§Ø±ÙØ©Ù",
                "ÙˆÙØ±Ø§Ø­ÙØªÙÙ‡Ø§ Ù…ÙÙ…Ø²ÙˆØ¬ÙØ©ÙŒ Ø¨ÙØ¹ÙÙ†Ø§Ø¡Ù"
            ),
            Verse(
                "ÙÙÙ„Ø§ ØªÙÙ…Ø´Ù ÙŠÙÙˆÙ…Ø§Ù‹ ÙÙŠ Ø«ÙÙŠØ§Ø¨Ù Ù…ÙØ®ÙŠÙ„ÙØ©Ù",
                "ÙÙØ¥ÙÙ†Ù‘ÙÙƒÙ Ù…ÙÙ† Ø·ÙŠÙ†Ù Ø®ÙÙ„ÙÙ‚ØªÙ ÙˆÙÙ…Ø§Ø¡Ù"
            ),
            Verse(
                "Ù„ÙÙ‚ÙÙ„Ù‘Ù Ø§Ù…Ø±ÙØ¤ÙŒ ØªÙÙ„Ù‚Ø§Ù‡Ù Ù„ÙÙ„Ù‘ÙÙ‡Ù Ø´Ø§ÙƒÙØ±Ø§Ù‹",
                "ÙˆÙÙ‚ÙÙ„Ù‘Ù Ø§Ù…Ø±ÙØ¤ÙŒ ÙŠÙØ±Ø¶Ù‰ Ù„ÙÙ‡Ù Ø¨ÙÙ‚ÙØ¶Ø§Ø¡Ù"
            ),
            Verse(
                "ÙˆÙÙ„ÙÙ„Ù‘ÙÙ‡Ù Ù†ÙØ¹Ù…Ø§Ø¡ÙŒ Ø¹ÙÙ„ÙÙŠÙ†Ø§ Ø¹ÙØ¸ÙŠÙ…ÙØ©ÙŒ",
                "ÙˆÙÙ„ÙÙ„Ù‘ÙÙ‡Ù Ø¥ÙØ­Ø³Ø§Ù†ÙŒ ÙˆÙÙÙØ¶Ù„Ù Ø¹ÙØ·Ø§Ø¡Ù"
            ),
        ],
    )
    example_verse = example_poem.verses[3]
    instruction = f"""
You are in expert in the Arabic language and the Arabic literature. You are tasked with explaining a verse from an Arabic poem and giving a description of an image that illustrates and caputres the implicit meaning behind the verse to be used as a visual aid in a presentation about it. You are also given a large snippet of the poem and information about it as context. Lastly, you should translate the description of the image into English.

Example: -------------
{example_poem}\n\nØ§Ù„Ø¨ÙŠØª: "{example_verse}"

Expected Output: -------------
Ø§Ù„Ø´Ø±Ø­: Ù„Ø§ØªØªÙƒØ¨Ø± ÙˆØªÙ…Ø´ÙŠ Ø¨Ø®ÙŠÙ„Ø§Ø¡ Ø­ØªÙ‰ ÙˆÙ„Ùˆ ÙƒÙ†Øª ØºÙ†ÙŠØ§ ÙˆØªÙ„Ø¨Ø³ Ø£Ø­Ø³Ù† Ø§Ù„Ø«ÙŠØ§Ø¨ Ù„Ø£Ù†Ùƒ ÙÙŠ Ø§Ù„Ø£ØµÙ„ Ù…Ø®Ù„ÙˆÙ‚ Ù…Ù† ØªØ±Ø§Ø¨ ÙˆÙ…Ø§Ø¡
Ø§Ù„ØµÙˆØ±Ø©: Ø´Ø®Øµ ÙŠØ±ØªØ¯ÙŠ Ù…Ù„Ø§Ø¨Ø³ ÙØ§Ø®Ø±Ø© ÙˆÙŠØ¨Ø¯Ùˆ Ø¹Ù„ÙŠÙ‡ Ø§Ù„ØªÙƒØ¨Ø± Ø§Ù„Ù…ÙØ±Ø· Ù„ÙƒÙ† Ø£Ù…Ø§Ù…Ù‡ Ø¨Ø±ÙƒØ© Ù…Ø§Ø¡ ÙŠÙƒØ§Ø¯ ÙŠØ³Ù‚Ø· ÙÙŠÙ‡Ø§ Ù„Ø£Ù†Ù‡ Ø±Ø§ÙØ¹ Ø§Ù†ÙÙ‡ Ù…Ù† Ø§Ù„ØºØ±ÙˆØ± ÙˆÙ„Ø§ ÙŠØ±Ø§Ù‡Ø§
Image: A person wears luxurious clothes and appears extremely arrogant, but in front of him is a puddle of water in which he almost falls because he raises his nose out of arrogance and does not see it.
""".strip()
    output = ask_gpt(instruction, f'{poem}\n\nØ§Ù„Ø¨ÙŠØª: "{verse}"')
    def get(x): return (re.findall(f'{x}: (.*)', output) or [''])[0]
    verse.explanation = get('Ø§Ù„Ø´Ø±Ø­')
    verse.illustration = get('Ø§Ù„ØµÙˆØ±Ø©')
    verse.illustration_en = get('Image')
    return verse

"""The code defines several components related to working with Arabic poems. The purpose of this code is to provide an organized way to work with Arabic poems, including representing their descriptive data and content, as well as generating explanations and visual descriptions for specific verses. This could be useful for tasks such as literary analysis, poetry presentation, or educational applications related to Arabic poetry.

## Full Example
"""

!ngrok kill

"""**write the poem name in title, only in arabic letters**"""

title = "ØµÙˆØª ØµÙÙŠØ± Ø§Ù„Ø¨Ù„Ø¨Ù„"
found = df[df["poem_title"].str.contains(title)]
poem = poems[found.sample(1).index[0]]

arabic_html(poem)

# import pickle
# from flask import Flask, request, render_template

# app = Flask(__name__)

# class Verse:
#     def __init__(self, text, explanation, illustration, illustration_en):
#         self.text = text
#         self.explanation = explanation
#         self.illustration = illustration
#         self.illustration_en = illustration_en
#         self.audio = None
#         self.image = None

# # def explain_and_illustrate(poem):
# #     # Implement your logic to generate verses with explanations and illustrations
# #     return verses

# # def generate_audio(text):
# #     # Implement your logic to generate audio for the given text
# #     return "Generated audio for: " + text

# # def generate_image(prompt):
# #     # Implement your logic to generate an image based on the given prompt
# #     return "Generated image for prompt: " + prompt

# def arabic_html(text):
#     # Implement your logic to convert Arabic text to HTML
#     return text

# @app.route('/', methods=['GET', 'POST'])
# def index():
#     if request.method == 'POST':
#         # Get the input from the form
#         input_data = request.form['input_data']

#         # Process the input and generate the output
#         poem = input_data  # Assuming the input is the poem
#         cache_file = f"{hash(str(poem))}.pkl"
#         try:
#             with open(cache_file, "rb") as file:
#                 poem = pickle.load(file)
#             found = True
#         except FileNotFoundError:
#             found = False

#         output = ""
#         for verse in explain_and_illustrate(poem):
#             # show verse
#             output += arabic_html(f"<center>{'*' * 5} {verse.text} {'*' * 5}</center>") + "<br>"
#             # show explanation
#             output += arabic_html(verse.explanation) + "<br>"
#             # play verse
#             if verse.audio is None:
#                 verse.audio = generate_audio(str(verse))
#             output += verse.audio + "<br>"
#             # print illustration
#             output += arabic_html("___ Ù‡Ù†Ø§ Ù†ØµÙˆØ± ___") + "<br>"
#             output += verse.illustration + "<br>"
#             # show generated image
#             if verse.image is None:
#                 prompt = f"{verse.illustration_en}\n\n{poem.era.value}"
#                 verse.image = generate_image(prompt)
#             output += str(verse.image) + "<br>"
#             # print english illustration
#             output += "___ English ___<br>"
#             output += verse.illustration_en + "<br>"
#             # print separator
#             output += "-" * 30 + "<br>"

#         # save the poem if not cached
#         if not found:
#             with open(cache_file, "wb") as file:
#                 pickle.dump(poem, file)

#         # Render the output template with the result
#         return render_template('output.html', output=output)

#     # If the request is GET, render the input template
#     return render_template('input.html')

# # Start Ngrok tunnel
# public_url = ngrok.connect(5000)
# print(f" * ngrok tunnel \"{public_url}\" -> \"http://127.0.0.1:5000\"")

# # Run Flask app
# app.run(port=5000, use_reloader=False)

# # HTML templates
# input_html = """
# <!DOCTYPE html>
# <html>
# <head>
#     <title>Input Page</title>
# </head>
# <body>
#     <h1>Enter Input</h1>
#     <form method="post">
#         <textarea name="input_data" rows="5"></textarea>
#         <br>
#         <input type="submit" value="Submit">
#     </form>
# </body>
# </html>
# """

# output_html = """
# <!DOCTYPE html>
# <html>
# <head>
#     <title>Output Page</title>
# </head>
# <body>
#     <h1>Output</h1>
#     {{ output|safe }}
# </body>
# </html>
# """

# # Create the template files
# with open('templates/input.html', 'w', encoding='utf-8') as f:
#     f.write(input_html)

# with open('templates/output.html', 'w', encoding='utf-8') as f:
#     f.write(output_html)

import pickle

# try to load the poem if already cached
cache_file = f"{hash(str(poem))}.pkl"
try:
    with open(cache_file, "rb") as file:
        poem = pickle.load(file)
    found = True
except FileNotFoundError:
    found = False


# display the verses
for verse in explain_and_illustrate(poem):
    # show verse
    display.display(arabic_html(f"<center>{'*' * 5} {verse} {'*' * 5}</center>"))

    # show explanation
    display.display(arabic_html(verse.explanation))

    # play verse
    if getattr(verse, "audio", None) is None:
        verse.audio = generate_audio(str(verse))
    display.display(verse.audio)

    # print illustration
    display.display(arabic_html("___ Ù‡Ù†Ø§ Ù†ØµÙˆØ± ___"))
    display.display(display.HTML(verse.illustration))

    # show generated image
    if getattr(verse, "image", None) is None:
        prompt = f"{verse.illustration_en}\n\n{poem.era.value}"
        verse.image = generate_image(prompt)
    display.display(verse.image)

    # print english illustration
    display.display(display.HTML("___ English ___"))
    display.display(display.HTML(verse.illustration_en))

    # print separator
    display.display(display.HTML("-" * 30))


# save the poem if not cached
if not found:
    with open(cache_file, "wb") as file:
        pickle.dump(poem, file)

"""We have written this code to iterate through each line of the poem, calling a function to explain and describe the line, and then extract any identified image prompts from the function's output. We generated an audio representation of the verse using the generate_audio function. The corresponding image that was generated earlier was then displayed. The goal is to create a presentation or interactive experience that combines the poem's text, images, and audio."""

video_path = 'output.mp4'
save_slide_show(video_path, [(v.image, v.audio) for v in poem])
display.Video(video_path, embed=True)